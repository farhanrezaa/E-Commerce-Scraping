{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "import sys\n",
    "import linecache\n",
    "import selenium.webdriver as webdriver\n",
    "import selenium.webdriver.support.ui as ui\n",
    "import pymongo\n",
    "import datetime\n",
    "import urllib.request\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep \n",
    "from pymongo import MongoClient \n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_function(url):\n",
    "    url_1 = url\n",
    "\n",
    "    for i in range(1,28) :\n",
    "        driver = webdriver.Firefox()\n",
    "        url = url_1 + str(i)\n",
    "        driver.get(url)\n",
    "        # Get scroll height.\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "        while True:\n",
    "\n",
    "            # Scroll down to the bottom.\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load the page.\n",
    "            time.sleep(randint(1,50))\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height.\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            if new_height == last_height:\n",
    "\n",
    "                break\n",
    "\n",
    "            last_height = new_height\n",
    "        base = driver.find_elements_by_css_selector('a.jss433 > span > img:nth-child(1)')\n",
    "\n",
    "        for x in range(len(base)):\n",
    "            image = base[x].get_attribute('src')\n",
    "            urllib.request.urlretrieve(image, str(i) + str(x) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraping_function('https://www.hijup.com/id/categories/pakaian-wanita?h_source_url=%2Fid%2Fcategories%2Fpakaian-wanita&product_search%5Bpage%5D=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\uzla\\\\Documents\\\\Scraping Instagram'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
